{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local.env file\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model='gpt-3.5-turbo'):\n",
    "    messages = [{'role': 'user', 'content': prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=100,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting Principles\n",
    "1. Principle 1: Write clear and specific instructions\n",
    "2. Principle 2: Give the model time to “think”\n",
    "## Tactics\n",
    "Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
    "Delimiters can be anything like: ```, \"\"\", < >, <tag> </tag>, :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"You should express what you want a model to do by \\ providing instructions that are as clear and \\ specific as you can possibly make them. \\\n",
    "This will guide the model towards the desired output, \\ and reduce the chances of receiving irrelevant \\ or incorrect responses. Don't confuse writing a \\ clear prompt with writing a short prompt. \\ In many cases, longer prompts provide more clarity \\ and context for the model, which can lead to \\ more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = get_completion (prompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prompt injectors so be careful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tactic 2: ask for structure output like HTML, JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tactic 3: check weather conditions are satisfied. Check assumptions required to do the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tactic 4 = few shot prompting \n",
    "Give successful examples of completing tasks then ask model to perform the task "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle 2\n",
    "Give the model time to think"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tactics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tactic 1: Specify the steps to complete a task "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tactic 2: instruct the model to work out its own solution before rushing to a conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Limitations:\n",
    "## Hallucinations - Make statements that sound plausible but are not true."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
