{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have changed the topic for next week to Decision Trees and Random Forests, therefore the pre-class HW has changed.  You now need to watch these two videos and comment with one thing you learned to this message. You can watch them in less than 30 mins if in a rush.  You no longer need to do the original preclass HW (the TIFDF video).\n",
    "Decision Trees with StatQuest (20min)\n",
    "Random Forest Part 1 With StatQuest (10min)\n",
    "Optional, watch Random Forest Part 2 (12 min)\n",
    "Extra optional, watch StatQuest XGBOOST (30min - 2hrs)\n",
    "XGBoost is considered the most powerful ML algo that is not a neural network.\n",
    "There will be a short quiz on this material at the beginning of next class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video 1 Decision and classification trees:\n",
    "https://www.youtube.com/watch?v=_L39rN6gz7Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree makes a statement and decides on whether it is true or false.\n",
    "When a decision tree classifies things into categories it is called a classification tree.\n",
    "When a decision tree predicts numerical values it is called a regression tree.\n",
    "You can mix data types in the same tree. \n",
    "\n",
    "1. Root Node or the root for the top level\n",
    "2. then below the top level is internal nodes and branches \n",
    "3. leaf nodes that lead to nothing afterward\n",
    "\n",
    "Impure\n",
    "Gini Impurity \n",
    "Lowest impurity goes to the top of the tree\n",
    "\n",
    "Pruning to deal with overfitting\n",
    "\n",
    "Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video 2 StatQuest: Random Forest Part 1 - Building, Using and Evaluating\n",
    "https://www.youtube.com/watch?v=J4Wdy0Wc_xQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest are made out of decision trees.\n",
    "\"But not good in practice\" Noted.\n",
    "\n",
    "1. Great with the data used to create them but not flexible when it comes to classifying new samples. \n",
    "2. Simple with flexibility to improve accuracy\n",
    "3. bootstrap dataset - Bootstrapping is any test or metric that uses random sampling with replacement, and falls under the broader class of resampling methods.\n",
    "4. Using random variables from the data and using the subset of that data\n",
    "4. Run the data in the trees you made and see what options gets the most votes.\n",
    "\n",
    "Bootstrapping the data plus using aggregate to make a decision is called \"Bagging\"\n",
    "\"Out of bag dataset\" where not all the data is within a decision tree\n",
    "\n",
    "We use the square of the number of variables when choosing the amount of variables to randomly sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video 3 StatQuest: Random Forests Part 2: Missing data and clustering\n",
    "https://www.youtube.com/watch?v=sQ870aTKqiM&t=10s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Missing data in OG dataset used to create the random forest\n",
    "2. Missing data in the new sample that you want to categorize\n",
    "\n",
    "Proximity Matrix to track similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video 4 XGBoost Part 1 (of 4): Regression\n",
    "https://www.youtube.com/watch?v=OtD8wVaFm6E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
